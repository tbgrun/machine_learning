# Polynomial Regression
### 1. Import Libraries
    import numpy as np
    import pandas as pd
    from sklearn.model_selection import train_test_split, GridSearchCV
    from sklearn.preprocessing import PolynomialFeatures, StandardScaler
    from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElsaticNet
    from sklearn.pipeline import Pipeline
    from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
    from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score, roc_curve
    from sklearn.ensemble import RandomForestRegressor
    from sklearn.inspection import permutation_importance
    import matplotlib.pyplot as plt
### 2. Identify Feature and Target Variables
    X = df.drop(columns='target_column_name') # features
    y = df['target_column_name'] # target
### 3. Split Data into Train and Test Sets
[klick here to get to "Data Splitting"](https://github.com/tbgrun/machine_learning/blob/main/03%20-%20Data%20Splitting/00%20-%20Data%20Splitting.md)
### 4. Build Pipeline for Linear Regression with Polynomial Features
    pipeline = Pipeline([
        ('poly_features', PolynomialFeatures(degree=2)),
        ('scaler', StandardScaler()),
        ('regressor', LinearRegression())
    ])
More Information
* [Polynomial Features](https://github.com/tbgrun/machine_learning/blob/main/02%20-%20Data%20Wrangling/08%20-%20Feature%20Engineering.md#12-polynomial-features)
* [Scaling](https://github.com/tbgrun/machine_learning/blob/main/02%20-%20Data%20Wrangling/10%20-%20Scaling.md)
* [Linear Regression](https://github.com/tbgrun/machine_learning/blob/main/05%20-%20Supervised%20Machine%20Learning/01.01%20-%20Linear%20Regression.md)
### 5. Hyperparameter Tuning
#### 5.1 Manual Fine Tuning
##### 5.1.1 Fine Tune
    log_reg_tuned = LogisticRegression(max_iter=200, penalty='l2', C=1.0, solver='lbfgs')
    log_reg_tuned.fit(X_train_scaled, y_train)
    y_pred_tuned = log_reg_tuned.predict(X_test_scaled)
* **max_iter:** maximum number of iterations.
* **penalty:** defines type of regularization. Options: l1, l2, elastic, none. l2 is default.
* **C:** controls the strength of regularization. Lower values (c=0.1) apply stronger regularization (reduce model complexity, prevent overfitting). Higher values (c=100) apply less regularization (capture more complex data, prone to overfitting).
* **solver:** defines the algorithm used for search. Options: lbfgs, liblinear, sag, saga. Default is lbfgs.
##### 5.1.2 Evaluation
###### 5.1.2.1 Evaluation Metrics
    mae = mean_absolute_error(y_test, y_pred_tuned)
    mse = mean_squared_error(y_test, y_pred_tuned)
    rmse = mean_squared_error(y_test, y_pred_tuned, squared=False)  # Set squared=False to get RMSE
    r2 = r2_score(y_test, y_pred)
###### 5.1.2.2 Visualization
    plt.scatter(y_test, y_pred_tuned)
    plt.xlabel("Actual Values")
    plt.ylabel("Predicted Values")
    plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='orange', linestyle='--')  # baseline
    plt.show()
#### 5.2 Automated Hyperparameter Tuning
##### 5.2.1 Define GridSearchCV Parameters
    poly_feat_degree_gridsearch = [2, 3, 4]
    alpha_gridsearch = [0.1, 1.0, 10.0]
    l1_gridsearch = [0.1, 0.5, 0.9]
##### 5.2.2 Setup GridSearchCV
    parameter_grid = [
         {
             'poly_features__degree': poly_feat_degree_gridsearch,  # degrees to try
             'regressor': [LinearRegression()]
         },
         {
             'poly_features__degree': poly_feat_degree_gridsearch,
             'regressor': [Ridge()],
             'regressor__alpha': alpha_gridsearch  # regularization strength
         },
         {
             'poly_features__degree': poly_feat_degree_gridsearch,
             'regressor': [Lasso()],
             'regressor__alpha': alpha_gridsearch  # regularization strength
         },
         {
             'poly_features__degree': poly_feat_degree_gridsearch,
             'regressor': [ElasticNet()],
             'regressor__alpha': alpha_gridsearch,  # regularization strength
             'regressor__l1_ratio': l1_gridsearch  # regularization strength
         }
     ]
##### 5.2.3 Run Hyperparameter Tuning
    grid_search = GridSearchCV(pipeline, parameter_grid, cv=5, scoring='neg_mean_squared_error')
    grid_search.fit(X_train, y_train) # fit model
    best_model = grid_search.best_estimator_
##### 5.2.4 Evaluation
[klick here to get to "Performance Metrics Overview"](https://github.com/tbgrun/machine_learning/blob/main/99%20-%20Supplementary%20Materials/01%20-%20Performance%20Metrics%20Overview.md)

    mae = mean_absolute_error(y_test, y_pred)
    mse = mean_squared_error(y_test, y_pred)
    rmse = mean_squared_error(y_test, y_pred, squared=False)  # Set squared=False to get RMSE
    r2 = r2_score(y_test, y_pred)
##### 5.2.5 Visualization
    plt.scatter(y_test, y_pred)
    plt.xlabel("Actual Values")
    plt.ylabel("Predicted Values")
    plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='orange', linestyle='--')  # baseline
    plt.show()
### 6. Feature Importance Analysis
    result = permutation_importance(best_model, X_test, y_test, n_repeats=10, random_state=42)
    feature_importances = result.importances_mean
    for i, importance in enumerate(feature_importances):
        print(f"Feature {i}: Importance {importance}")
